{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qm6I_g1XfslG"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "UUqH3d5_fBqg",
    "outputId": "48a02df3-dda9-4af1-ce76-d0fec02aabb1"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers \n",
    "from tensorflow.keras.layers import BatchNormalization as bn\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmIfKG5LdC_t"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJAD-VrYfFki"
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MO2ZZSu6fPmW",
    "outputId": "e8d85a94-addc-4aac-cdd5-f24d00c9692f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 51\n"
     ]
    }
   ],
   "source": [
    "# Download from https://www.kaggle.com/datasets/andrewmvd/liver-tumor-segmentation\n",
    "\n",
    "img_path = glob(\"data/volume_pt*/volume-*.nii\")\n",
    "mask_path = glob(\"data/segmentations/segmentation-*.nii\")\n",
    "\n",
    "if len(img_path) == 0 or len(mask_path) == 0 or len(img_path) > len(mask_path):\n",
    "    raise Exception(\"Incorrect rata found ({} volumes and {} segmentations)!\".format(len(img_path), len(mask_path)))\n",
    "\n",
    "print(\"Number of images:\", len(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UJoMBveXlc1"
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQiTREr-Ydea"
   },
   "outputs": [],
   "source": [
    "img_path.sort(key=natural_keys)\n",
    "mask_path.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cz392SQ8fviu"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5H1bN8MdLoH"
   },
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, 10e-8, 1.-10e-8)\n",
    "    loss = - (y_true * K.log(y_pred) * 0.90 + (1 - y_true) * K.log(1 - y_pred) * 0.10)\n",
    "    \n",
    "    return K.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tp9RVRHwrxhc"
   },
   "outputs": [],
   "source": [
    "# Reference : https://github.com/dk67604/LITS-Challenge-Liver-Segmentation/blob/master/experiments/keras_realtime_train.ipynb\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-KnEpEjfYbO"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvwhakozfY87"
   },
   "outputs": [],
   "source": [
    "input_shape = [64, 64, 1]\n",
    "dropout_rate = 0.3\n",
    "l2_lambda = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPW2F07zfZGr"
   },
   "outputs": [],
   "source": [
    "def u_net(input_shape, dropout_rate, l2_lambda):\n",
    "  \n",
    "  # Encoder\n",
    "  input = Input(shape = input_shape, name = \"input\")\n",
    "  conv1_1 = Conv2D(32, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv1_1\")(input)\n",
    "  conv1_1 = bn(name = \"conv1_1_bn\")(conv1_1)\n",
    "  conv1_2 = Conv2D(32, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv1_2\")(conv1_1)\n",
    "  conv1_2 = bn(name = \"conv1_2_bn\")(conv1_2)\n",
    "  pool1 = MaxPooling2D(name = \"pool1\")(conv1_2)\n",
    "  drop1 = Dropout(dropout_rate)(pool1)\n",
    "  \n",
    "  conv2_1 = Conv2D(64, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv2_1\")(pool1)\n",
    "  conv2_1 = bn(name = \"conv2_1_bn\")(conv2_1)\n",
    "  conv2_2 = Conv2D(64, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv2_2\")(conv2_1)\n",
    "  conv2_2 = bn(name = \"conv2_2_bn\")(conv2_2)\n",
    "  pool2 = MaxPooling2D(name = \"pool2\")(conv2_2)\n",
    "  drop2 = Dropout(dropout_rate)(pool2)\n",
    "  \n",
    "  conv3_1 = Conv2D(128, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv3_1\")(pool2)\n",
    "  conv3_1 = bn(name = \"conv3_1_bn\")(conv3_1)\n",
    "  conv3_2 = Conv2D(128, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv3_2\")(conv3_1)\n",
    "  conv3_2 = bn(name = \"conv3_2_bn\")(conv3_2)\n",
    "  pool3 = MaxPooling2D(name = \"pool3\")(conv3_2)\n",
    "  drop3 = Dropout(dropout_rate)(pool3)  \n",
    "\n",
    "  conv4_1 = Conv2D(256, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv4_1\")(pool3)\n",
    "  conv4_1 = bn(name = \"conv4_1_bn\")(conv4_1)\n",
    "  conv4_2 = Conv2D(256, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv4_2\")(conv4_1)\n",
    "  conv4_2 = bn(name = \"conv4_2_bn\")(conv4_2)\n",
    "  pool4 = MaxPooling2D(name = \"pool4\")(conv4_2)\n",
    "  drop4 = Dropout(dropout_rate)(pool4)  \n",
    "\n",
    "  conv5_1 = Conv2D(512, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv5_1\")(pool4)\n",
    "  conv5_1 = bn(name = \"conv5_1_bn\")(conv5_1)\n",
    "  conv5_2 = Conv2D(512, (3, 3), padding = \"same\", activation='relu', kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv5_2\")(conv5_1)\n",
    "  conv5_2 = bn(name = \"conv5_2_bn\")(conv5_2)\n",
    "  \n",
    "  # Decoder\n",
    "  upconv6 = Conv2DTranspose(256,(2, 2), strides=(2, 2), padding='same')(conv5_2)\n",
    "  upconv6 = Dropout(dropout_rate)(upconv6)\n",
    "  concat6 = concatenate([conv4_2, upconv6], name = \"concat6\")\n",
    "  conv6_1 = Conv2D(256, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv6_1\")(concat6)\n",
    "  conv6_1 = bn(name = \"conv6_1_bn\")(conv6_1)\n",
    "  conv6_2 = Conv2D(256, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv6_2\")(conv6_1)\n",
    "  conv6_2 = bn(name = \"conv6_2_bn\")(conv6_2)\n",
    "    \n",
    "  upconv7 = Conv2DTranspose(128,(2, 2), strides=(2, 2), padding='same')(conv6_2)\n",
    "  upconv7 = Dropout(dropout_rate)(upconv7)\n",
    "  concat7 = concatenate([conv3_2, upconv7], name = \"concat7\")\n",
    "  conv7_1 = Conv2D(128, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv7_1\")(concat7)\n",
    "  conv7_1 = bn(name = \"conv7_1_bn\")(conv7_1)\n",
    "  conv7_2 = Conv2D(128, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv7_2\")(conv7_1)\n",
    "  conv7_2 = bn(name = \"conv7_2_bn\")(conv7_2)\n",
    "\n",
    "  upconv8 = Conv2DTranspose(64,(2, 2), strides=(2, 2), padding='same')(conv7_2)\n",
    "  upconv8 = Dropout(dropout_rate)(upconv8)\n",
    "  concat8 = concatenate([conv2_2, upconv8], name = \"concat8\")\n",
    "  conv8_1 = Conv2D(64, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv8_1\")(concat8)\n",
    "  conv8_1 = bn(name = \"conv8_1_bn\")(conv8_1)\n",
    "  conv8_2 = Conv2D(64, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv8_2\")(conv8_1)\n",
    "  conv8_2 = bn(name = \"conv8_2_bn\")(conv8_2)\n",
    "\n",
    "  upconv9 = Conv2DTranspose(32,(2, 2), strides=(2, 2), padding='same')(conv8_2)\n",
    "  upconv9 = Dropout(dropout_rate)(upconv9)\n",
    "  concat9 = concatenate([conv1_2, upconv9], name = \"concat9\")\n",
    "  conv9_1 = Conv2D(32, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv9_1\")(concat9)\n",
    "  conv9_1 = bn(name = \"conv9_1_bn\")(conv9_1)\n",
    "  conv9_2 = Conv2D(32, (3, 3), padding = \"same\", kernel_regularizer=regularizers.l2(l2_lambda), name = \"conv9_2\")(conv9_1)\n",
    "  conv9_2 = bn(name = \"conv9_2_bn\")(conv9_2)\n",
    "  dropout = Dropout(dropout_rate)(conv9_2)\n",
    "  \n",
    "  conv10 = Conv2D(1, (1, 1), padding = \"same\", activation = 'sigmoid', name = \"conv10\")(dropout)\n",
    "\n",
    " \n",
    "  model = Model(input, conv10)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "id": "mDG0ni4kfaRv",
    "outputId": "3e421fea-81ff-4443-a34c-db76e800f266"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:32:49.919777: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = u_net(input_shape, dropout_rate, l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8K2PTGT6zLPJ",
    "outputId": "391977e5-6f77-480c-f5e0-97c92409ae51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iyy5fU_TdNAC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTGOjBUcrxh4"
   },
   "source": [
    "### Patch Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_ratio = []\n",
    "for i in range(16 + 1):\n",
    "  patch_ratio.append(32 * i)\n",
    "\n",
    "def patch_sampling(img, mask, patch_ratio, pos_neg_ratio, threshold):\n",
    "  \n",
    "  temp_mask = mask\n",
    "  \n",
    "  temp_mask[temp_mask == 1] = 0\n",
    "  temp_mask[temp_mask == 2] = 1\n",
    "  \n",
    "  positive_patch = []\n",
    "  positive_mask = []\n",
    "  \n",
    "  negative_patch = []\n",
    "  negative_mask = []\n",
    "  \n",
    "  negative_set = []\n",
    "  \n",
    "  \n",
    "  for i in range(temp_mask.shape[2]):\n",
    "    for x_bin in range(2, len(patch_ratio)):\n",
    "        for y_bin in range(2, len(patch_ratio)):\n",
    "          img_patch = img[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin], i]\n",
    "          mask_patch = temp_mask[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin], i]\n",
    "          _, count = np.unique(mask_patch, return_counts = True)\n",
    "          \n",
    "          if len(count) == 2:\n",
    "            mask_percentage = count[1] / sum(count) * 100\n",
    "          \n",
    "            if threshold < mask_percentage :\n",
    "              positive_patch.append(img_patch)\n",
    "              positive_mask.append(mask_patch)\n",
    "          \n",
    "          \n",
    "          elif len(count) == 1:\n",
    "            \n",
    "            temp_list = []\n",
    "            temp_list.append(img_patch)\n",
    "            temp_list.append(mask_patch)\n",
    "            \n",
    "            negative_set.append(temp_list)\n",
    "  \n",
    "  shuffle(negative_set)\n",
    "  \n",
    "  negative_set_to_use = negative_set[:len(positive_patch) * pos_neg_ratio]\n",
    "  for negative_set in negative_set_to_use:\n",
    "    negative_patch.append(negative_set[0])\n",
    "    negative_mask.append(negative_set[1])\n",
    "  \n",
    "  negative_set_to_use = []\n",
    "  \n",
    "  return positive_patch, positive_mask, negative_patch, negative_mask\n",
    "\n",
    "\n",
    "def getTotals(from_percent, to_percent, unique_suffix=None):\n",
    "    from_position = int(len(img_path) * from_percent)\n",
    "    to_position = int(len(img_path) * to_percent)\n",
    "    total_patch = []\n",
    "    total_mask = []\n",
    "    for i in range(from_position, to_position):\n",
    "        img_3D = nib.load(img_path[i]).get_fdata()\n",
    "        mask_3D = nib.load(mask_path[i]).get_fdata()\n",
    "\n",
    "        pos_patch, pos_mask, neg_patch, neg_mask = patch_sampling(img_3D, mask_3D, patch_ratio, 3, 3.0)\n",
    "        total_patch += (pos_patch + neg_patch)\n",
    "        total_mask += (pos_mask + neg_mask)\n",
    "\n",
    "        print(\"Image {0}/{1}: # of patches = {2} | # of total images = {3}\".format(\n",
    "            format(i+1, '>2'), \n",
    "                   len(img_path),\n",
    "                   format(len(pos_patch) + len(neg_patch), '>5'),\n",
    "                   format(len(total_patch), '>5')))\n",
    "    total_patch = np.array(total_patch).reshape((len(total_patch), 64, 64, 1))\n",
    "    total_mask = np.array(total_mask).reshape((len(total_mask), 64, 64, 1))\n",
    "    \n",
    "    if unique_suffix is not None:\n",
    "        np.save(\"model/total_patch_{}.npy\".format(unique_suffix), total_patch)\n",
    "        np.save(\"model/total_mask_{}.npy\".format(unique_suffix), total_mask)\n",
    "    \n",
    "    return total_patch, total_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6iziBCzLEx_"
   },
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSUFQeq4rxiL"
   },
   "source": [
    "### Compile, fit and save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: 12 volumes is aroung 30 GB RAM, so using 24% is the limit in my case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "_vXNvKMlrxh5",
    "outputId": "29443061-6feb-4a41-8ca1-2bfb3f2f6374"
   },
   "outputs": [],
   "source": [
    "total_patch_train, total_mask_train = getTotals(0, 0.24, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SyZPw3Y0BQZ"
   },
   "outputs": [],
   "source": [
    "total_patch_train = np.load(\"model/total_patch_train.npy\")\n",
    "total_mask_train = np.load(\"model/total_mask_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tOTd9R_O0XhU",
    "outputId": "d81bd2a8-c373-4695-fc8f-13e14093038c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27096, 64, 64, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wJgocqjPfftL",
    "outputId": "17fdb922-9bc6-4da7-eb01-1b0788346ebe"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = weighted_binary_crossentropy, metrics = [dice_coef])\n",
    "\n",
    "# Fitting takes a long time, 1-2 hours\n",
    "model.fit(total_patch, total_mask, batch_size = 512, epochs = 10)\n",
    "\n",
    "# Save model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Save model weights to HDF5\n",
    "model.save_weights(\"model/model_weights.h5\")\n",
    "\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUtE2jBp3-er"
   },
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fvIvg1zA4NU-",
    "outputId": "e779e683-71a2-46b4-bfb2-a10491b40f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_1 (Conv2D)               (None, 64, 64, 32)   320         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1_1_bn (BatchNormalization  (None, 64, 64, 32)  128         ['conv1_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1_2 (Conv2D)               (None, 64, 64, 32)   9248        ['conv1_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_2_bn (BatchNormalization  (None, 64, 64, 32)  128         ['conv1_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 32, 32, 32)   0           ['conv1_2_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_1 (Conv2D)               (None, 32, 32, 64)   18496       ['pool1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2_1_bn (BatchNormalization  (None, 32, 32, 64)  256         ['conv2_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2 (Conv2D)               (None, 32, 32, 64)   36928       ['conv2_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_2_bn (BatchNormalization  (None, 32, 32, 64)  256         ['conv2_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 16, 16, 64)   0           ['conv2_2_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_1 (Conv2D)               (None, 16, 16, 128)  73856       ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv3_1_bn (BatchNormalization  (None, 16, 16, 128)  512        ['conv3_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2 (Conv2D)               (None, 16, 16, 128)  147584      ['conv3_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_2_bn (BatchNormalization  (None, 16, 16, 128)  512        ['conv3_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)           (None, 8, 8, 128)    0           ['conv3_2_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_1 (Conv2D)               (None, 8, 8, 256)    295168      ['pool3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv4_1_bn (BatchNormalization  (None, 8, 8, 256)   1024        ['conv4_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2 (Conv2D)               (None, 8, 8, 256)    590080      ['conv4_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_2_bn (BatchNormalization  (None, 8, 8, 256)   1024        ['conv4_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " pool4 (MaxPooling2D)           (None, 4, 4, 256)    0           ['conv4_2_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_1 (Conv2D)               (None, 4, 4, 512)    1180160     ['pool4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv5_1_bn (BatchNormalization  (None, 4, 4, 512)   2048        ['conv5_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2 (Conv2D)               (None, 4, 4, 512)    2359808     ['conv5_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_2_bn (BatchNormalization  (None, 4, 4, 512)   2048        ['conv5_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 8, 8, 256)   524544      ['conv5_2_bn[0][0]']             \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 8, 256)    0           ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " concat6 (Concatenate)          (None, 8, 8, 512)    0           ['conv4_2_bn[0][0]',             \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv6_1 (Conv2D)               (None, 8, 8, 256)    1179904     ['concat6[0][0]']                \n",
      "                                                                                                  \n",
      " conv6_1_bn (BatchNormalization  (None, 8, 8, 256)   1024        ['conv6_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv6_2 (Conv2D)               (None, 8, 8, 256)    590080      ['conv6_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv6_2_bn (BatchNormalization  (None, 8, 8, 256)   1024        ['conv6_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 128)  131200     ['conv6_2_bn[0][0]']             \n",
      " spose)                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16, 16, 128)  0           ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " concat7 (Concatenate)          (None, 16, 16, 256)  0           ['conv3_2_bn[0][0]',             \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv7_1 (Conv2D)               (None, 16, 16, 128)  295040      ['concat7[0][0]']                \n",
      "                                                                                                  \n",
      " conv7_1_bn (BatchNormalization  (None, 16, 16, 128)  512        ['conv7_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv7_2 (Conv2D)               (None, 16, 16, 128)  147584      ['conv7_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv7_2_bn (BatchNormalization  (None, 16, 16, 128)  512        ['conv7_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 64)  32832       ['conv7_2_bn[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32, 32, 64)   0           ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " concat8 (Concatenate)          (None, 32, 32, 128)  0           ['conv2_2_bn[0][0]',             \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv8_1 (Conv2D)               (None, 32, 32, 64)   73792       ['concat8[0][0]']                \n",
      "                                                                                                  \n",
      " conv8_1_bn (BatchNormalization  (None, 32, 32, 64)  256         ['conv8_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv8_2 (Conv2D)               (None, 32, 32, 64)   36928       ['conv8_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv8_2_bn (BatchNormalization  (None, 32, 32, 64)  256         ['conv8_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 32)  8224        ['conv8_2_bn[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64, 64, 32)   0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " concat9 (Concatenate)          (None, 64, 64, 64)   0           ['conv1_2_bn[0][0]',             \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv9_1 (Conv2D)               (None, 64, 64, 32)   18464       ['concat9[0][0]']                \n",
      "                                                                                                  \n",
      " conv9_1_bn (BatchNormalization  (None, 64, 64, 32)  128         ['conv9_1[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv9_2 (Conv2D)               (None, 64, 64, 32)   9248        ['conv9_1_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv9_2_bn (BatchNormalization  (None, 64, 64, 32)  128         ['conv9_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64, 64, 32)   0           ['conv9_2_bn[0][0]']             \n",
      "                                                                                                  \n",
      " conv10 (Conv2D)                (None, 64, 64, 1)    33          ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,771,297\n",
      "Trainable params: 7,765,409\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/model_weights.h5\")\n",
    "loaded_model.summary()\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_6telMu2lhA"
   },
   "source": [
    "### Conversion utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngq1ZUab3F6r"
   },
   "outputs": [],
   "source": [
    "def slice_to_patch(slice, patch_ratio):\n",
    "  \n",
    "  slice[slice == 1] = 0\n",
    "  slice[slice == 2] = 1\n",
    "  \n",
    "  patch_list = []\n",
    "  \n",
    "  for x_bin in range(2, len(patch_ratio)):\n",
    "    for y_bin in range(2, len(patch_ratio)):\n",
    "      patch = slice[patch_ratio[x_bin-2] : patch_ratio[x_bin], patch_ratio[y_bin - 2] : patch_ratio[y_bin]]\n",
    "      patch = patch.reshape(patch.shape + (1,))\n",
    "      patch_list.append(patch)\n",
    "  \n",
    "  return np.array(patch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsbWGHyE6nXh"
   },
   "outputs": [],
   "source": [
    "def patch_to_slice(patch, patch_ratio, input_shape, conf_threshold):\n",
    "  \n",
    "  slice = np.zeros((512, 512, 1))\n",
    "  row_idx = 0\n",
    "  col_idx = 0\n",
    "  \n",
    "  for i in range(len(patch)):\n",
    "    \n",
    "    slice[patch_ratio[row_idx]:patch_ratio[row_idx + 2], patch_ratio[col_idx]:patch_ratio[col_idx + 2]][patch[i] > conf_threshold] = 1\n",
    "    \n",
    "    col_idx += 1\n",
    "    \n",
    "    if i != 0 and (i+1) % 15 == 0:\n",
    "      row_idx += 1\n",
    "      col_idx = 0\n",
    "  \n",
    "  return slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test totals,save them to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_patch, total_test_mask = getTotals(0.30, 0.45, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model accuracy, MSE, dice coef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 252s 11s/step - loss: 0.1577 - dice_coef: 0.0981 - accuracy: 0.9387 - mse: 0.0783 - false_negatives: 0.0000e+00 - false_positives: 1729087.0000\n",
      "[('loss', 0.1577272266149521), ('dice_coef', 0.09807351231575012), ('accuracy', 0.9387029409408569), ('mse', 0.078289695084095), ('false_negatives', 0.0), ('false_positives', 1729087.0)]\n"
     ]
    }
   ],
   "source": [
    "total_test_patch = np.load(\"model/total_patch_test.npy\")\n",
    "total_test_mask = np.load(\"model/total_mask_test.npy\")\n",
    "\n",
    "loaded_model.compile(optimizer = adam, loss = weighted_binary_crossentropy, metrics = [dice_coef, \"accuracy\", \"mse\", tf.keras.metrics.FalseNegatives(thresholds=0), tf.keras.metrics.FalsePositives()])\n",
    "\n",
    "evaluations = loaded_model.evaluate(total_test_patch, total_test_mask, batch_size = 512)\n",
    "print(list(zip(loaded_model.metrics_names, evaluations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exaple visualization of model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ja3zZagsrxjI",
    "outputId": "18f2fab5-420c-4d1a-f5df-4b1b4b5e046a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find false positive rate.\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "image_index = 13\n",
    "img_ex = nib.load(img_path[image_index]).get_fdata()\n",
    "mask_ex = nib.load(mask_path[image_index]).get_fdata()\n",
    "\n",
    "mask_ex[mask_ex == 1] = 0\n",
    "\n",
    "for i in range(mask_ex.shape[2]):\n",
    "    _, count = np.unique(mask_ex[:, :, i], return_counts=True)\n",
    "    if len(count) > 1 and count[1] > 300:\n",
    "        \n",
    "        patch_ex = slice_to_patch(img_ex[:, :, i], patch_ratio)\n",
    "        prediction = loaded_model.predict(patch_ex)\n",
    "        prediction_mask = patch_to_slice(prediction, patch_ratio, input_shape, conf_threshold = 0.97)\n",
    "        \n",
    "        fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize = ((15, 15)))\n",
    "        \n",
    "        ax1.imshow(np.rot90(img_ex[:, :, i], 3), cmap = 'bone')\n",
    "        ax1.set_title(\"Image\", fontsize = \"x-large\")\n",
    "        ax1.grid(False)\n",
    "        ax2.imshow(np.rot90(mask_ex[:, :, i], 3), cmap = 'bone')\n",
    "        ax2.set_title(\"Mask (Actual)\", fontsize = \"x-large\")\n",
    "        ax2.grid(False)\n",
    "        ax3.imshow(np.rot90(prediction_mask.reshape((512, 512)), 3), cmap = 'bone')\n",
    "        ax3.set_title(\"Mask (Prediction)\", fontsize = \"x-large\")\n",
    "        ax3.grid(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Model Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
